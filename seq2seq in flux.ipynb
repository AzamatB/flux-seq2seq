{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "using CuArrays, Flux, Statistics, Random\n",
        "\n",
        "FILE = \"D:/downloads/fra-eng/eng-fra.txt\"\n",
        "\n",
        "mutable struct Lang\n",
        "    name\n",
        "    word2index\n",
        "    word2count\n",
        "    index2word\n",
        "    n_words\n",
        "end\n",
        "\n",
        "Lang(name) = Lang(\n",
        "    name,\n",
        "    Dict{String, Int}(),\n",
        "    Dict{String, Int}(),\n",
        "    Dict{Int, String}(1=>\"SOS\", 2=>\"EOS\", 3=>\"UNK\", 4=>\"PAD\"),\n",
        "    4)\n",
        "\n",
        "function (l::Lang)(sentence::String)\n",
        "    for word in split(sentence, \" \")\n",
        "            if word ∉ keys(l.word2index)\n",
        "                l.word2index[word] = l.n_words + 1\n",
        "                l.word2count[word] = 1\n",
        "                l.index2word[l.n_words + 1] = word\n",
        "                l.n_words += 1\n",
        "            else\n",
        "                l.word2count[word] += 1\n",
        "            end\n",
        "    end\n",
        "end\n",
        "\n",
        "function normalizeString(s)\n",
        "    s = strip(lowercase(s))\n",
        "    s = replace(s, r\"([.!?,])\"=>s\" \\1\")\n",
        "    s = replace(s, \"'\"=>\" ' \")\n",
        "    return s\n",
        "end\n",
        "\n",
        "function readLangs(lang1, lang2; rev=false)\n",
        "    println(\"Reading lines...\")\n",
        "    lines = readlines(FILE)\n",
        "    pairs = [normalizeString.(pair) for pair in split.(lines, \"\\t\")]\n",
        "    if rev\n",
        "        pairs = reverse.(pairs)\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "    end\n",
        "    return(input_lang, output_lang, pairs)\n",
        "end\n",
        "        \n",
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = [\n",
        "    \"i am \", \"i ' m \",\n",
        "    \"he is \", \"he ' s \",\n",
        "    \"she is \", \"she ' s \",\n",
        "    \"you are \", \"you ' re \",\n",
        "    \"we are \", \"we ' re \",\n",
        "    \"they are \", \"they ' re \"]\n",
        "        \n",
        "function filterPair(pair)\n",
        "    return(false ∉ (length.(split.(pair, \" \")) .<= MAX_LENGTH) && true ∈ (startswith.(pair[1], eng_prefixes)))\n",
        "end\n",
        "\n",
        "function prepareData(lang1, lang2; rev=false)\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2; rev=rev)\n",
        "    println(\"Read $(length(pairs)) sentence pairs.\")\n",
        "    pairs = [pair for pair in pairs if filterPair(pair)]\n",
        "    println(\"Trimmed to $(length(pairs)) sentence pairs.\\n\")\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for pair in pairs\n",
        "        push!(xs, pair[1])\n",
        "        push!(ys, pair[2])\n",
        "    end\n",
        "    println(\"Counting words...\")\n",
        "    for pair in pairs\n",
        "        input_lang(pair[2])\n",
        "        output_lang(pair[1])\n",
        "    end\n",
        "    println(\"Counted words:\")\n",
        "    println(\"• \", input_lang.name, \": \", input_lang.n_words)\n",
        "    println(\"• \", output_lang.name, \": \", output_lang.n_words)\n",
        "    return(input_lang, output_lang, xs, ys)\n",
        "end\n",
        "\n",
        "fr, eng, xs, ys = prepareData(\"fr\", \"eng\")\n",
        "indices = shuffle([1:length(xs)...])\n",
        "xs = xs[indices]\n",
        "ys = ys[indices];\n",
        "        \n",
        "BATCH_SIZE = 64\n",
        "\n",
        "indexesFromSentence(lang, sentence) = append!(get.(Ref(lang.word2index), split(lowercase(sentence), \" \"), 3), 2)\n",
        "\n",
        "function batch(data, batch_size, voc_size; gpu=true)\n",
        "    chunks = Iterators.partition(data, batch_size)\n",
        "    batches = []\n",
        "    for chunk in chunks\n",
        "        max_length = maximum(length.(chunk))\n",
        "        chunk = map(sentence->append!(sentence, fill(4, max_length-length(sentence))), chunk)\n",
        "        chunk = hcat(reshape.(chunk, :, 1)...)\n",
        "        batch = []\n",
        "        for i in 1:size(chunk, 1)\n",
        "            if gpu\n",
        "                push!(batch, cu(Flux.onehotbatch(chunk[i, :], [1:voc_size...])))\n",
        "            else\n",
        "                push!(batch, Flux.onehotbatch(chunk[i, :], [1:voc_size...]))\n",
        "            end\n",
        "        end\n",
        "        push!(batches, batch)\n",
        "    end\n",
        "    return(batches)\n",
        "end\n",
        "\nx, y = batch.([indexesFromSentence.([eng], xs), indexesFromSentence.([fr], ys)], [BATCH_SIZE], [eng.n_words, fr.n_words]; gpu=true);"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 154883 sentence pairs.\n",
            "Trimmed to 11645 sentence pairs.\n",
            "\n",
            "Counting words...\n",
            "Counted words:\n",
            "• fr: 4831\n",
            "• eng: 3047\n"
          ]
        }
      ],
      "execution_count": 69,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "struct Encoder\n",
        "    embedding\n",
        "    dropout\n",
        "    rnn\n",
        "    out\n",
        "end\n",
        "Encoder(voc_size::Integer; h_size::Integer=HIDDEN, dropout::Number=DROPOUT) = Encoder(\n",
        "    param(Flux.glorot_uniform(h_size, voc_size)),\n",
        "    Dropout(dropout),\n",
        "    GRU(h_size, h_size),\n",
        "    Dense(h_size, h_size))\n",
        "function (e::Encoder)(x)\n",
        "    x = map(x->e.dropout(e.embedding*x), x)\n",
        "    enc_outputs = e.rnn.(x)\n",
        "    h = e.out(enc_outputs[end])\n",
        "    return(enc_outputs, h)\n",
        "end\n",
        "Flux.@treelike Encoder"
      ],
      "outputs": [],
      "execution_count": 70,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ u_i^t = v^T tanh(W_1'h_i+W_2'd_t) $\n",
        "\n",
        "$ a_i^t = softmax(u_i^t) $\n",
        "\n$ \\sum\\limits_{i=1}^{T_a} a_i^t h_i$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "struct Attention\n",
        "    W1\n",
        "    W2\n",
        "    v\n",
        "end\n",
        "Attention(h_size) = Attention(\n",
        "    Dense(h_size, h_size),\n",
        "    Dense(h_size, h_size),\n",
        "    param(Flux.glorot_uniform(1, h_size)))\n",
        "function (a::Attention)(enc_outputs, d)\n",
        "    U = [a.v*tanh.(x) for x in a.W1.(enc_outputs).+[a.W2(d)]]\n",
        "    A = softmax(vcat(U...))\n",
        "    out = sum([gpu(collect(A[i, :]')) .* h for (i, h) in enumerate(enc_outputs)])\n",
        "end\n",
        "Flux.@treelike Attention"
      ],
      "outputs": [],
      "execution_count": 71,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "W1 = Dense(16, 16)|>gpu\n",
        "W2 = Dense(16, 16)|>gpu\n",
        "v = param(Flux.glorot_uniform(1,16))|>gpu\n",
        "\n",
        "A = softmax(vcat([v*tanh.(x) for x in W1.(enc_outputs).+[W2(d)]]...))\n",
        "collect(A[1, :]')\n",
        "gpu(collect(A[2, :]')).*enc_outputs[1]"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "m = Chain(x->gpu(Attention(16))(x...), x->sum(x))\n",
        "opt = SGD(params(m))\n",
        "#m((enc_outputs, d))\n",
        "Flux.train!(m, [[(enc_outputs, d)]], opt)"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "enc_outputs, d = (gpu.([rand(16, 32), rand(16, 32)]), rand(16,32)|>gpu)"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "struct Decoder\n",
        "    embedding\n",
        "    attention\n",
        "    rnn\n",
        "    output\n",
        "end\n",
        "Decoder(h_size, voc_size) = Decoder(\n",
        "    param(Flux.glorot_uniform(h_size, voc_size)),\n",
        "    Attention(h_size),\n",
        "    GRU(h_size*2, h_size),\n",
        "    Dense(h_size, voc_size, relu))\n",
        "function (d::Decoder)(x, enc_outputs; dropout=0)\n",
        "    x = d.embedding * x\n",
        "    x = Dropout(dropout)(x)\n",
        "    decoder_state = d.rnn.state\n",
        "    context = d.attention(enc_outputs, decoder_state)\n",
        "    x = d.rnn([x; context])\n",
        "    x = softmax(d.output(x))\n",
        "    return(x)\n",
        "end\n",
        "Flux.@treelike Decoder"
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN = 128\n",
        "LEARNING_RATE = 0.03\n",
        "DROPOUT = 0.2;"
      ],
      "outputs": [],
      "execution_count": 83,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testEncoder = Encoder(eng.n_words)|>gpu\n",
        "testDecoder = Decoder(HIDDEN, fr.n_words)|>gpu;"
      ],
      "outputs": [],
      "execution_count": 84,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function model(encoder::Encoder, decoder::Decoder, x, y; teacher_forcing = 0.5, dropout=DROPOUT, voc_size=fr.n_words)\n",
        "    total_loss = 0\n",
        "    max_length = length(y)\n",
        "    batch_size = size(x[1], 2)\n",
        "    Flux.reset!.([encoder, decoder])\n",
        "    enc_outputs, h = encoder(x)\n",
        "    decoder_input = Flux.onehotbatch(ones(batch_size), [1:voc_size...])\n",
        "    decoder.rnn.state = h\n",
        "    for i in 1:max_length\n",
        "        use_teacher_forcing = rand() < teacher_forcing\n",
        "        decoder_output = decoder(decoder_input, enc_outputs; dropout=dropout)\n",
        "        total_loss += loss(decoder_output, y[i])\n",
        "        if use_teacher_forcing\n",
        "            decoder_input = y[i]\n",
        "        else\n",
        "            decoder_input = Flux.onehotbatch(Flux.onecold(decoder_output.data), [1:voc_size...])\n",
        "        end\n",
        "    end\n",
        "    return(total_loss)\n",
        "end\n",
        "\nmodel(x, y) = model(testEncoder, testDecoder, x, y; dropout = 0.05)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 85,
          "data": {
            "text/plain": [
              "model (generic function with 3 methods)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 85,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function model(encoder::Encoder, decoder::Decoder, x; reset=true, voc_size=fr.n_words)\n",
        "    result = []\n",
        "    if reset Flux.reset!.([encoder, decoder]) end\n",
        "    enc_outputs, h = encoder(x)\n",
        "    decoder_input = Flux.onehot(1, [1:voc_size...])\n",
        "    decoder.rnn.state = h\n",
        "    for i in 1:12\n",
        "        decoder_output = Flux.onecold(decoder(decoder_input, enc_outputs))\n",
        "        if decoder_output[1] == 2 break end\n",
        "        push!(result, decoder_output...)\n",
        "    end\n",
        "    return(result)\n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 86,
          "data": {
            "text/plain": [
              "model (generic function with 3 methods)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 86,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lossmask = ones(fr.n_words)|>gpu\n",
        "lossmask[4] = 0\n",
        "\n",
        "loss(logits, target) = Flux.crossentropy(logits, target; weight=lossmask)\n",
        "\nopt = SGD(params(testEncoder, testDecoder), LEARNING_RATE)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 87,
          "data": {
            "text/plain": [
              "#43 (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 87,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function partitionTrainTest(x, y, at)\n",
        "    n = length(x)\n",
        "    idx = shuffle(1:n)\n",
        "    train_idx = view(idx, 1:floor(Int, at*n))\n",
        "    test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
        "    train_x, test_x = x[train_idx,:], x[test_idx,:]\n",
        "    train_y, test_y = y[train_idx,:], y[test_idx,:]\n",
        "    return(train_x, train_y, test_x, test_y)\n",
        "end\n",
        "\ntrain_x, train_y, test_x, test_y = partitionTrainTest(x, y, 0.90);"
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for i in 1:EPOCHS\n",
        "    Flux.train!(model, zip(train_x, train_y), opt)\n",
        "    println(\"loss: \", mean(model.(test_x, test_y)).data)\n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 27.571863\n",
            "loss: 27.486343\n",
            "loss: 26.830484\n",
            "loss: 26.309473\n",
            "loss: 26.658197\n",
            "loss: 26.309603\n",
            "loss: 25.964235\n",
            "loss: 25.645933\n",
            "loss: 25.657099\n",
            "loss: 25.125471\n",
            "loss: 25.051096\n",
            "loss: 24.310825\n",
            "loss: 24.868933\n",
            "loss: 24.411522\n",
            "loss: 24.269579\n",
            "loss: 24.17102\n",
            "loss: 24.438782\n",
            "loss: 23.875217"
          ]
        }
      ],
      "execution_count": 91,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for i in 1:EPOCHS\n",
        "    Flux.train!(model, zip(train_x, train_y), opt)\n",
        "    println(\"loss: \", mean(model.(test_x, test_y)).data)\n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 63.385242\n",
            "loss: 62.951447\n",
            "loss: 62.48296\n",
            "loss: 61.928158\n",
            "loss: 61.14286\n",
            "loss: 59.63839\n",
            "loss: 54.74136\n",
            "loss: 49.10149\n",
            "loss: 47.900692\n",
            "loss: 46.31653\n",
            "loss: 44.378407\n",
            "loss: 42.588562\n",
            "loss: 40.99242\n",
            "loss: 39.650463\n",
            "loss: 38.72285\n",
            "loss: 38.132557\n",
            "loss: 37.71355\n",
            "loss: 37.39871\n",
            "loss: 37.14562\n",
            "loss: 36.930775\n"
          ]
        }
      ],
      "execution_count": 79,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function predict(encoder, decoder, sentence::String)\n",
        "    sentence = normalizeString(sentence)\n",
        "    input = append!(get.(Ref(eng.word2index), split(lowercase(sentence), \" \"), 3), 2)\n",
        "    input = [Flux.onehot(word, [1:eng.n_words...]) for word in input]\n",
        "    output = model(encoder, decoder, input)\n",
        "    output = get.(Ref(fr.index2word), output, \"UNK\")\n",
        "    println(output)\n",
        "end"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 81,
          "data": {
            "text/plain": [
              "predict (generic function with 1 method)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 81,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(testEncoder, testDecoder, \"she's doing her thing\")\n",
        "predict(testEncoder, testDecoder, \"you're too skinny\")\n",
        "predict(testEncoder, testDecoder, \"He is singing\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"il\", \"est\", \"'\", \"de\", \"de\", \"'\", \".\", \".\", \".\", \".\", \".\", \".\"]\n",
            "[\"il\", \"'\", \"'\", \"de\", \"'\", \"'\", \".\", \".\", \".\", \".\", \".\", \".\"]\n",
            "[\"il\", \"est\", \"'\", \"'\", \"'\", \".\", \".\", \".\", \".\", \".\", \".\", \".\"]\n"
          ]
        }
      ],
      "execution_count": 90,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "julia-1.0"
    },
    "language_info": {
      "file_extension": ".jl",
      "name": "julia",
      "mimetype": "application/julia",
      "version": "1.0.1"
    },
    "kernelspec": {
      "name": "julia-1.0",
      "language": "julia",
      "display_name": "Julia 1.0.1"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}